# Customer Transactions 
This project prototypes a secure, scalable data pipeline using Google Cloud. It ingests customer and transaction data, transforms it using Apache Beam, and exposes analytics-ready views in BigQuery.

## Features
- Data ingestion from GCS to BigQuery
- Schema validation and cleansing
- Monthly and lifetime spend analytics
- Modular Python code with tests
- CI/CD with GitHub Actions

## ğŸ—ï¸ Architecture Overview

cust-trans/
â”œâ”€â”€ pipeline/                  # Python transformation logic
â”‚   â”œâ”€â”€ transforms.py
â”‚   â””â”€â”€ test_transforms.py
â”œâ”€â”€ terraform/                 # Terraform infrastructure setup
â”‚   â”œâ”€â”€ main.tf                # Core resources (GCS, BigQuery, IAM)
â”‚   â”œâ”€â”€ variables.tf           # Input variables
â”‚   â””â”€â”€  outputs.tf            # Output values
â”œâ”€â”€ data/                     # data used for tables
â”‚   â”œâ”€â”€ cutomers.csv          #dummy customer profile data
â”‚   â””â”€â”€ transactions.csv      #dummy raw transactions logs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ python-ci.yml

## ğŸš€ Setup Instructions
1. Enable GCP APIs: Dataflow, BigQuery, Storage
2. Run `terraform apply` to provision infra
3. Upload CSVs to GCS
4. Execute `beam_custmers_pipeline.py` & `beam_transactions_pipeline.py`via Dataflow
5. Create materialized tables in BigQuery

### ğŸ” GCP Permissions
Ensure the following APIs are enabled:
- Cloud Storage
- Dataflow
- BigQuery
- IAM

Create a service account with roles:
- `roles/dataflow.worker`
- `roles/bigquery.dataEditor`
- `roles/storage.objectAdmin`

### âš™ï¸ Terraform Deployment
```bash
cd terraform
terraform init
terraform apply
